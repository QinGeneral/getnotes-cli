"""çŸ¥è¯†åº“ç¬”è®°ä¸‹è½½å™¨ â€” ä¸‹è½½çŸ¥è¯†åº“å†…çš„ç¬”è®°èµ„æºå¹¶ä¿å­˜ä¸º Markdown"""

import json
import logging
import os
import time
from datetime import datetime
from pathlib import Path

import httpx

from getnotes_cli.auth import AuthToken
from getnotes_cli.config import REQUEST_DELAY
from getnotes_cli.markdown import (
    get_file_extension,
    sanitize_filename,
)
from getnotes_cli.notebook import fetch_notebook_resources

logger = logging.getLogger(__name__)


class NotebookDownloader:
    """çŸ¥è¯†åº“ç¬”è®°ä¸‹è½½å™¨"""

    def __init__(
        self,
        token: AuthToken,
        output_dir: Path,
        *,
        delay: float = REQUEST_DELAY,
        force: bool = False,
        save_json: bool = False,
    ):
        self.token = token
        self.output_dir = output_dir
        self.delay = delay
        self.force = force
        self.save_json = save_json

        self.client = httpx.Client(timeout=60)
        self.stats = {"notes": 0, "files": 0, "skipped": 0}
        # note_id â†’ existing folder Path mapping (populated by _scan_existing_notes)
        self._existing_notes: dict[str, Path] = {}

    def download_notebook(self, notebook: dict) -> dict:
        """ä¸‹è½½å•ä¸ªçŸ¥è¯†åº“çš„æ‰€æœ‰ç¬”è®°ã€‚

        Args:
            notebook: çŸ¥è¯†åº“ä¿¡æ¯ï¼ˆæ¥è‡ª fetch_notebooksï¼‰

        Returns:
            ç»Ÿè®¡ç»“æœ
        """
        name = notebook.get("name", "æœªå‘½åçŸ¥è¯†åº“")
        topic_id_alias = notebook.get("id_alias", "")
        root_dir = notebook.get("root_dir", {})
        directory_id = root_dir.get("id", 0)
        total_count = notebook.get("extend_data", {}).get("all_resource_count", "?")

        # åˆ›å»ºçŸ¥è¯†åº“ç›®å½•
        notebook_dir = self.output_dir / "notebooks" / sanitize_filename(name)
        notebook_dir.mkdir(parents=True, exist_ok=True)

        # æ‰«æå·²æœ‰ç¬”è®°æ–‡ä»¶å¤¹ï¼Œå»ºç«‹ note_id â†’ folder æ˜ å°„
        self._existing_notes = {}
        self._scan_existing_notes(notebook_dir)

        logger.info("=" * 60)
        logger.info("ğŸ“š çŸ¥è¯†åº“: %s", name)
        logger.info("   å†…å®¹æ€»æ•°: %s | ID: %s", total_count, topic_id_alias)
        logger.info("   è¾“å‡ºç›®å½•: %s", notebook_dir)
        logger.info("=" * 60)

        local_stats = {"notes": 0, "files": 0, "skipped": 0}

        # é€’å½’ä¸‹è½½æ ¹ç›®å½•åŠå…¶æ‰€æœ‰å­ç›®å½•
        self._download_directory(
            topic_id_alias, directory_id, notebook_dir, local_stats
        )

        # ç”ŸæˆçŸ¥è¯†åº“ç´¢å¼•
        self._generate_notebook_index(notebook, notebook_dir, local_stats)

        # æ±‡æ€»ç»Ÿè®¡
        for k in local_stats:
            self.stats[k] += local_stats[k]

        logger.info("âœ… çŸ¥è¯†åº“ [%s] ä¸‹è½½å®Œæˆ: %d ç¯‡ç¬”è®°, %d ä¸ªæ–‡ä»¶",
                     name, local_stats['notes'], local_stats['files'])

        return local_stats

    def _download_directory(
        self,
        topic_id_alias: str,
        directory_id: int,
        target_dir: Path,
        stats: dict,
        depth: int = 0,
    ) -> None:
        """é€’å½’ä¸‹è½½æŸä¸ªç›®å½•ä¸‹çš„æ‰€æœ‰èµ„æºå’Œå­ç›®å½•ã€‚

        Args:
            topic_id_alias: çŸ¥è¯†åº“åˆ«å ID
            directory_id: ç›®å½• ID
            target_dir: æœ¬åœ°ç›®æ ‡ç›®å½•
            stats: ç»Ÿè®¡å­—å…¸ï¼ˆåŸåœ°ä¿®æ”¹ï¼‰
            depth: é€’å½’æ·±åº¦ï¼ˆç”¨äºæ—¥å¿—ç¼©è¿›ï¼‰
        """
        indent = "  " * depth
        notes_dir = target_dir / "notes"
        files_dir = target_dir / "files"
        page = 1

        while True:
            logger.info("%sğŸ“„ æ­£åœ¨æ‹‰å–ç¬¬ %d é¡µ (dir=%s)...", indent, page, directory_id)

            content = fetch_notebook_resources(
                self.token, topic_id_alias, directory_id, page=page, client=self.client
            )

            # å¤„ç†å­ç›®å½•ï¼ˆä»…åœ¨ç¬¬ä¸€é¡µæ—¶ï¼Œé¿å…é‡å¤ï¼‰
            if page == 1:
                directories = content.get("directories") or []
                if directories:
                    logger.info("%s  ğŸ“‚ å‘ç° %d ä¸ªå­ç›®å½•", indent, len(directories))
                    for sub_dir in directories:
                        sub_name = sub_dir.get("name", "æœªå‘½åç›®å½•")
                        sub_id = sub_dir.get("id", 0)
                        sub_target = target_dir / sanitize_filename(sub_name)
                        sub_target.mkdir(parents=True, exist_ok=True)

                        logger.info("%s  ğŸ“‚ è¿›å…¥å­ç›®å½•: %s", indent, sub_name)
                        self._download_directory(
                            topic_id_alias, sub_id, sub_target, stats, depth=depth + 1
                        )
                        time.sleep(self.delay)

            # å¤„ç†èµ„æº
            resources = content.get("resources", []) or []
            has_next = content.get("has_next", 0)

            if not resources and page == 1 and not (content.get("directories") or []):
                logger.info("%s  âš ï¸ è¯¥ç›®å½•æš‚æ— å†…å®¹ã€‚", indent)
                break

            if resources:
                logger.info("%s  æœ¬é¡µ %d ä¸ªèµ„æº:", indent, len(resources))
                for resource in resources:
                    resource_type = resource.get("resource_type", "")
                    if resource_type == "NOTE":
                        notes_dir.mkdir(exist_ok=True)
                        self._process_note_resource(resource, notes_dir)
                        stats["notes"] += 1
                    elif resource_type == "FILE":
                        files_dir.mkdir(parents=True, exist_ok=True)
                        self._process_file_resource(resource, files_dir)
                        stats["files"] += 1
                    else:
                        logger.info("%s    â­ è·³è¿‡æœªçŸ¥ç±»å‹: %s", indent, resource_type)
                        stats["skipped"] += 1

            if not has_next:
                break

            page += 1
            time.sleep(self.delay)

    def download_all(self, notebooks: list[dict]) -> dict:
        """ä¸‹è½½æ‰€æœ‰çŸ¥è¯†åº“çš„ç¬”è®°ã€‚"""
        logger.info("ğŸš€ å¼€å§‹ä¸‹è½½ %d ä¸ªçŸ¥è¯†åº“...", len(notebooks))

        for i, nb in enumerate(notebooks, 1):
            name = nb.get("name", "æœªå‘½å")
            logger.info("[%d/%d] æ­£åœ¨å¤„ç†çŸ¥è¯†åº“: %s", i, len(notebooks), name)
            try:
                self.download_notebook(nb)
            except Exception as e:
                logger.error("  âŒ ä¸‹è½½å¤±è´¥: %s", e)
            time.sleep(self.delay)

        self._print_summary(len(notebooks))
        return self.stats

    # ------------------------------------------------------------------
    # èµ„æºå¤„ç†
    # ------------------------------------------------------------------

    def _process_note_resource(self, resource: dict, notes_dir: Path) -> None:
        """å¤„ç†ç¬”è®°ç±»å‹èµ„æº"""
        meta = resource.get("resource_note_meta_data", {})
        if not meta:
            return

        title = meta.get("title", "").strip() or "æ— æ ‡é¢˜"
        note_id = meta.get("note_id", meta.get("id", "unknown"))
        created_at = meta.get("created_at", "")

        # ä¼˜å…ˆé€šè¿‡ note_id åŒ¹é…å·²æœ‰æ–‡ä»¶å¤¹
        existing_dir = self._existing_notes.get(note_id)
        if existing_dir and not self.force:
            md_file = existing_dir / "note.md"
            if md_file.exists():
                logger.info("    â­ å·²å­˜åœ¨: %s", title[:40])
                return

        # ç”Ÿæˆæ–°çš„æ–‡ä»¶å¤¹å
        folder_name = self._make_note_folder_name(title, created_at, note_id)
        note_dir = existing_dir if existing_dir else notes_dir / folder_name

        if note_dir.exists() and not self.force:
            md_file = note_dir / "note.md"
            if md_file.exists():
                logger.info("    â­ å·²å­˜åœ¨: %s", title[:40])
                return

        note_dir.mkdir(parents=True, exist_ok=True)
        attachments_dir = note_dir / "attachments"

        # ä¸‹è½½é™„ä»¶
        self._download_note_attachments(meta, attachments_dir, note_dir)

        # ç”Ÿæˆ Markdown
        md_content = self._notebook_note_to_markdown(meta, attachments_dir, note_dir)
        (note_dir / "note.md").write_text(md_content, encoding="utf-8")

        # ä¿å­˜åŸå§‹ JSON
        if self.save_json:
            (note_dir / "note.json").write_text(
                json.dumps(resource, ensure_ascii=False, indent=2), encoding="utf-8"
            )

        display_title = title[:40] + "..." if len(title) > 40 else title
        logger.info("    âœ¨ %s", display_title)

    def _process_file_resource(self, resource: dict, files_dir: Path) -> None:
        """å¤„ç†æ–‡ä»¶ç±»å‹èµ„æº"""
        meta = resource.get("resource_file_meta_data", {})
        if not meta:
            return

        name = meta.get("name", "unknown_file")
        file_url = meta.get("file_url", "")

        if not file_url:
            logger.warning("    âš ï¸ æ–‡ä»¶æ— ä¸‹è½½é“¾æ¥: %s", name)
            return

        files_dir.mkdir(parents=True, exist_ok=True)
        save_path = files_dir / sanitize_filename(name, max_length=120)

        if save_path.exists() and not self.force:
            kb = save_path.stat().st_size / 1024
            logger.info("    â­ å·²å­˜åœ¨: %s (%.1f KB)", name, kb)
            return

        self._download_file(file_url, save_path)

    def _download_note_attachments(
        self, meta: dict, attachments_dir: Path, note_dir: Path
    ) -> bool:
        """ä¸‹è½½ç¬”è®°ç±»å‹èµ„æºçš„é™„ä»¶"""
        has = False

        # é™„ä»¶ï¼ˆéŸ³é¢‘/é“¾æ¥ç­‰ï¼‰
        for i, att in enumerate(meta.get("attachments", [])):
            att_url = att.get("url", "")
            att_type = att.get("type", "")
            if att_url and att_type != "link":
                has = True
                ext = get_file_extension(att_url, f".{att_type or 'bin'}")
                self._download_file(att_url, attachments_dir / f"attachment_{i + 1}{ext}")

        # å›¾ç‰‡
        images = (
            meta.get("original_images", [])
            or meta.get("small_images", [])
        )
        for i, img in enumerate(images):
            img_url = img if isinstance(img, str) else img.get("url", "") if isinstance(img, dict) else ""
            if img_url:
                has = True
                ext = get_file_extension(img_url, ".jpg")
                self._download_file(img_url, attachments_dir / f"image_{i + 1}{ext}")

        return has

    def _download_file(self, url: str, save_path: Path) -> bool:
        """ä¸‹è½½æ–‡ä»¶ï¼Œå·²å­˜åœ¨åˆ™è·³è¿‡"""
        try:
            if save_path.exists() and not self.force:
                return True

            save_path.parent.mkdir(parents=True, exist_ok=True)
            with self.client.stream("GET", url, timeout=60) as resp:
                resp.raise_for_status()
                with open(save_path, "wb") as f:
                    for chunk in resp.iter_bytes(8192):
                        f.write(chunk)

            kb = save_path.stat().st_size / 1024
            logger.info("      âœ… ä¸‹è½½: %s (%.1f KB)", save_path.name, kb)
            return True
        except Exception as e:
            logger.error("      âŒ ä¸‹è½½å¤±è´¥: %s - %s", save_path.name, e)
            return False

    # ------------------------------------------------------------------
    # Markdown è½¬æ¢
    # ------------------------------------------------------------------

    def _notebook_note_to_markdown(
        self, meta: dict, attachments_dir: Path, note_dir: Path
    ) -> str:
        """å°†çŸ¥è¯†åº“ç¬”è®°èµ„æºçš„ meta data è½¬ä¸º Markdown"""
        lines = []

        title = meta.get("title", "").strip()
        if title:
            lines.append(f"# {title}")
            lines.append("")

        # å…ƒä¿¡æ¯
        lines.append("## ğŸ“‹ ç¬”è®°ä¿¡æ¯")
        lines.append("")
        lines.append("| å±æ€§ | å€¼ |")
        lines.append("|------|-----|")
        lines.append(f"| ID | `{meta.get('note_id', '')}` |")
        lines.append(f"| æ¥æº | {meta.get('source', '')} |")
        lines.append(f"| ç±»å‹ | {meta.get('note_type', '')} |")
        lines.append(f"| å½•å…¥æ–¹å¼ | {meta.get('entry_type', '')} |")
        lines.append(f"| åˆ›å»ºæ—¶é—´ | {meta.get('created_at', '')} |")
        lines.append(f"| æ›´æ–°æ—¶é—´ | {meta.get('edit_time', '')} |")
        lines.append(f"| AI ç”Ÿæˆ | {'æ˜¯' if meta.get('is_ai_generated') else 'å¦'} |")

        tags = meta.get("tags", [])
        if tags:
            tag_names = ", ".join(f"`{t['name']}`" for t in tags if isinstance(t, dict))
            lines.append(f"| æ ‡ç­¾ | {tag_names} |")
        lines.append("")

        # æ­£æ–‡
        content = meta.get("content", "").strip()
        if content:
            lines.append("## ğŸ“ å†…å®¹")
            lines.append("")
            lines.append(content)
            lines.append("")

        # å¼•ç”¨å†…å®¹
        ref_content = meta.get("ref_content", "").strip()
        if ref_content:
            lines.append("## ğŸ“– å¼•ç”¨å†…å®¹")
            lines.append("")
            lines.append("> " + ref_content.replace("\n", "\n> "))
            lines.append("")

        # é™„ä»¶
        attachments = meta.get("attachments", [])
        if attachments:
            lines.append("## ğŸ”Š é™„ä»¶")
            lines.append("")
            for i, att in enumerate(attachments):
                att_type = att.get("type", "unknown")
                att_url = att.get("url", "")
                att_title = att.get("title", "")

                if att_type == "link":
                    if att_title and att_url:
                        lines.append(f"- ğŸ”— [{att_title}]({att_url})")
                    elif att_url:
                        lines.append(f"- ğŸ”— [{att_url}]({att_url})")
                elif att_url:
                    ext = get_file_extension(att_url, f".{att_type}")
                    att_filename = f"attachment_{i + 1}{ext}"
                    att_path = attachments_dir / att_filename
                    rel_path = os.path.relpath(att_path, note_dir)
                    lines.append(f"- **{att_type.upper()}**: [{att_filename}]({rel_path})")
                else:
                    lines.append(f"- **{att_type.upper()}**: (æ— é“¾æ¥)")
            lines.append("")

        # å›¾ç‰‡
        images = meta.get("original_images", []) or meta.get("small_images", [])
        if images:
            lines.append("## ğŸ–¼ï¸ å›¾ç‰‡")
            lines.append("")
            for i, img in enumerate(images):
                img_url = img if isinstance(img, str) else img.get("url", "") if isinstance(img, dict) else ""
                if img_url:
                    ext = get_file_extension(img_url, ".jpg")
                    img_filename = f"image_{i + 1}{ext}"
                    img_path = attachments_dir / img_filename
                    rel_path = os.path.relpath(img_path, note_dir)
                    lines.append(f"![å›¾ç‰‡ {i + 1}]({rel_path})")
                    lines.append("")

        # æ‰€å±çŸ¥è¯†åº“
        topics = meta.get("topics", [])
        if topics:
            lines.append("## ğŸ“š æ‰€å±çŸ¥è¯†åº“")
            lines.append("")
            for t in topics:
                if isinstance(t, dict):
                    lines.append(f"- {t.get('topic_name', '(æœªçŸ¥)')}")
            lines.append("")

        return "\n".join(lines)

    # ------------------------------------------------------------------
    # è¾…åŠ©æ–¹æ³•
    # ------------------------------------------------------------------

    def _scan_existing_notes(self, root_dir: Path) -> None:
        """é€’å½’æ‰«æç›®å½•ä¸‹æ‰€æœ‰å·²å­˜åœ¨çš„ note.jsonï¼Œå»ºç«‹ note_id â†’ folder æ˜ å°„ã€‚"""
        if not root_dir.exists():
            return

        for json_file in root_dir.rglob("note.json"):
            try:
                data = json.loads(json_file.read_text(encoding="utf-8"))
                # notebook_downloader ä¿å­˜çš„ JSON ç»“æ„æ˜¯æ•´ä¸ª resource å¯¹è±¡
                meta = data.get("resource_note_meta_data", data)
                note_id = meta.get("note_id", meta.get("id", ""))
                if note_id:
                    self._existing_notes[note_id] = json_file.parent
            except (json.JSONDecodeError, IOError):
                continue

        if self._existing_notes:
            logger.info("  ğŸ’¾ æ‰«æåˆ° %d ä¸ªå·²æœ‰ç¬”è®°", len(self._existing_notes))

    def _make_note_folder_name(
        self, title: str, created_at: str, note_id: str
    ) -> str:
        """ç”Ÿæˆç¬”è®°æ–‡ä»¶å¤¹å"""
        date_prefix = ""
        if created_at:
            try:
                dt = datetime.strptime(created_at, "%Y-%m-%d %H:%M:%S")
                date_prefix = dt.strftime("%Y%m%d_%H%M%S")
            except ValueError:
                date_prefix = created_at.replace(" ", "_").replace(":", "")

        base = f"{date_prefix}_{title}" if title else f"{date_prefix}_{note_id}"
        return sanitize_filename(base)

    def _generate_notebook_index(
        self, notebook: dict, notebook_dir: Path, stats: dict
    ) -> None:
        """ç”ŸæˆçŸ¥è¯†åº“ç´¢å¼•æ–‡ä»¶"""
        name = notebook.get("name", "æœªå‘½åçŸ¥è¯†åº“")
        index_path = notebook_dir / "INDEX.md"

        with open(index_path, "w", encoding="utf-8") as f:
            f.write(f"# ğŸ“š {name}\n\n")
            f.write(f"- å¯¼å‡ºæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write(f"- ç¬”è®°æ•°: {stats['notes']}\n")
            f.write(f"- æ–‡ä»¶æ•°: {stats['files']}\n\n")

            # åˆ—å‡ºç¬”è®°
            notes_dir = notebook_dir / "notes"
            if notes_dir.exists():
                dirs = sorted(d for d in notes_dir.iterdir() if d.is_dir())
                if dirs:
                    f.write("## ç¬”è®°åˆ—è¡¨\n\n")
                    f.write("| # | ç¬”è®° |\n")
                    f.write("|---|------|\n")
                    for i, d in enumerate(dirs, 1):
                        md_file = d / "note.md"
                        if md_file.exists():
                            f.write(f"| {i} | [{d.name}](notes/{d.name}/note.md) |\n")

            # åˆ—å‡ºæ–‡ä»¶
            files_dir = notebook_dir / "files"
            if files_dir.exists():
                files = sorted(f_item for f_item in files_dir.iterdir() if f_item.is_file())
                if files:
                    f.write("\n## æ–‡ä»¶åˆ—è¡¨\n\n")
                    f.write("| # | æ–‡ä»¶å | å¤§å° |\n")
                    f.write("|---|--------|------|\n")
                    for i, fi in enumerate(files, 1):
                        kb = fi.stat().st_size / 1024
                        f.write(f"| {i} | [{fi.name}](files/{fi.name}) | {kb:.1f} KB |\n")

    def _print_summary(self, total_notebooks: int) -> None:
        """æ‰“å°ä¸‹è½½æ€»ç»“"""
        logger.info("=" * 60)
        logger.info("ğŸ“Š å…¨éƒ¨çŸ¥è¯†åº“ä¸‹è½½æ€»ç»“")
        logger.info("=" * 60)
        logger.info("  ğŸ“š çŸ¥è¯†åº“æ•°:   %d", total_notebooks)
        logger.info("  ğŸ“ ç¬”è®°:       %d ç¯‡", self.stats['notes'])
        logger.info("  ğŸ“ æ–‡ä»¶:       %d ä¸ª", self.stats['files'])
        logger.info("  â­  è·³è¿‡:       %d ä¸ª", self.stats['skipped'])
        logger.info("  ğŸ“‚ è¾“å‡ºç›®å½•:   %s", self.output_dir.resolve())
        logger.info("=" * 60)
